{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "batch-fast-style-transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+cpcKKR/oEhUjIR47ph1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duskvirkus/colab-ml-art/blob/main/style_transfer/batch_fast_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQYtxZMH-snF"
      },
      "source": [
        "## GPU check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG2TztG1-gZ_",
        "outputId": "a056f76f-05fc-4267-c012-2951c2cb69c3"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-0403d88b-2170-bb4d-7f15-2859fe4be0ac)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4VV83q1-1ni"
      },
      "source": [
        "## Connect Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBOCIF09-zPW",
        "outputId": "7e3b3fac-4433-4c19-f159-f43692b139a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_TCd6wv-57Z"
      },
      "source": [
        "# Set to Tensorflow 2 and check version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFBIF_oz_COq",
        "outputId": "69649be4-3af5-4db7-9ae3-66cb6b4a3927"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scJypK0g_OmT"
      },
      "source": [
        "## Setup Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24f6TZWx_LVq"
      },
      "source": [
        "import functools\n",
        "import os\n",
        "\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "\n",
        "# Load TF-Hub module.\n",
        "\n",
        "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
        "hub_module = hub.load(hub_handle)\n",
        "\n",
        "def crop_center(image):\n",
        "  \"\"\"Returns a cropped square image.\"\"\"\n",
        "  shape = image.shape\n",
        "  new_shape = min(shape[1], shape[2])\n",
        "  offset_y = max(shape[1] - shape[2], 0) // 2\n",
        "  offset_x = max(shape[2] - shape[1], 0) // 2\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_y, offset_x, new_shape, new_shape)\n",
        "  return image\n",
        "\n",
        "@functools.lru_cache(maxsize=None)\n",
        "def load_image_url(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "  \"\"\"Loads and preprocesses images.\"\"\"\n",
        "  # Cache image file locally.\n",
        "  image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
        "  return load_image(image_path, image_size, preserve_aspect_ratio)\n",
        "\n",
        "def load_image(image_path, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "  \"\"\"Loads and preprocesses images.\"\"\"\n",
        "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
        "  img = tf.io.decode_image(\n",
        "      tf.io.read_file(image_path),\n",
        "      channels=3, dtype=tf.float32)[tf.newaxis, ...]\n",
        "  img = crop_center(img)\n",
        "  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
        "  return img\n",
        "\n",
        "def load_image_no_resize(image_path):\n",
        "  img = tf.io.decode_image(\n",
        "      tf.io.read_file(image_path),\n",
        "      channels=3, dtype=tf.float32)[tf.newaxis, ...]\n",
        "  return img"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-OsCUxa_n9z"
      },
      "source": [
        "## Set Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAl2KWon_t28"
      },
      "source": [
        "input_folder = '/content/drive/MyDrive/art/clip-vqgan-07-12-21' # path to folder of images to process\n",
        "style_images = '/content/drive/MyDrive/art/misc/color-fringe.png' # one image path or array of image paths to use as the style image. example: 'path/to/image' or ['path/to/image1', 'path/to/image2']\n",
        "output_folder = '/content/drive/MyDrive/art/style-transfer/test2' # where to save images (will create folders as needed, will overwrite existing files with the same name)\n",
        "resize_style_image = True # can change to False and it will use the style image size may lead to worse results"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVsJzQeEAZe_"
      },
      "source": [
        "## Run Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjQYhkqNBU3v"
      },
      "source": [
        "style_image_resize_size = (256, 256)\n",
        "\n",
        "# get image paths in input folder\n",
        "input_images = []\n",
        "for root, subdirs, files in os.walk(input_folder):\n",
        "    for filename in files:\n",
        "        input_images.append(os.path.join(root, filename))\n",
        "\n",
        "# style images loop\n",
        "if not isinstance(style_images, list):\n",
        "  style_images = [style_images]\n",
        "\n",
        "for style_im in style_images:\n",
        "  # load style image\n",
        "  style_image = None\n",
        "  if resize_style_image:\n",
        "    style_image = load_image(style_im, style_image_resize_size)\n",
        "  else:\n",
        "    style_image = load_image_no_resize(style_im)\n",
        "  style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "\n",
        "  # create save folder\n",
        "  style_output_dir = os.path.join(output_folder, style_im.split('/')[-1].split('.')[0])\n",
        "  os.makedirs(style_output_dir, exist_ok=True)\n",
        "\n",
        "  # process each image\n",
        "  for input_im in input_images:\n",
        "\n",
        "    content_image = load_image_no_resize(input_im)\n",
        "    outputs = hub_module(tf.constant(content_image), tf.constant(style_image))\n",
        "    tf.keras.preprocessing.image.save_img(os.path.join(style_output_dir, input_im.split('/')[-1].split('.')[0] + '.png'), outputs[0][0])\n"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}